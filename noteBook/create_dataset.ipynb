{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e1150a1-ec67-4aa7-b5f7-06c6c70d8aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¸ ç·ç”»åƒæ•°: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting confident samples:   1%|          | 80/10000 [00:01<02:30, 66.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… é¸ã°ã‚ŒãŸç”»åƒæ•°: 50\n",
      "\n",
      "ğŸ¯ é«˜ä¿¡é ¼åº¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã—ã¾ã—ãŸ â†’ C:\\Users\\sit\\wavelet_CGAN\\testdata3\\clean_dataset_50\n",
      "ğŸ§¾ ãƒ©ãƒ™ãƒ«CSV: C:\\Users\\sit\\wavelet_CGAN\\testdata3\\clean_dataset_50\\clean_dataset_labels.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#æŠ½å‡ºã‚³ãƒ¼ãƒ‰\n",
    "import os\n",
    "import random\n",
    "import csv\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "\n",
    "# === è¨­å®š ===\n",
    "base_dir = r\"C:\\Users\\sit\\wavelet_CGAN\\testdata3\\use_finish\\imagenetv2-top-images\\imagenetv2-top-images-format-val\"\n",
    "output_dir = r\"C:\\Users\\sit\\wavelet_CGAN\\testdata3\\clean_dataset_50\"#å‡ºåŠ›\n",
    "output_csv = os.path.join(output_dir, \"clean_dataset_labels.csv\")\n",
    "num_samples = 50 #ç”»åƒæ•°\n",
    "confidence_threshold = 0.7 #ç¢ºä¿¡åº¦\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# === ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒã‚¤ã‚¹ ===\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1)\n",
    "model = model.to(device).eval()\n",
    "imagenet_labels = models.MobileNet_V2_Weights.IMAGENET1K_V1.meta[\"categories\"]\n",
    "\n",
    "# === å‰å‡¦ç† ===\n",
    "preprocess = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# === å…¨ç”»åƒãƒªã‚¹ãƒˆä½œæˆ ===\n",
    "all_images = []\n",
    "for class_id in os.listdir(base_dir):\n",
    "    class_dir = os.path.join(base_dir, class_id)\n",
    "    if not os.path.isdir(class_dir): continue\n",
    "    try:\n",
    "        class_idx = int(class_id)\n",
    "    except ValueError:\n",
    "        continue\n",
    "    for img_name in os.listdir(class_dir):\n",
    "        if img_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            all_images.append((os.path.join(class_dir, img_name), class_idx))\n",
    "\n",
    "print(f\"ğŸ“¸ ç·ç”»åƒæ•°: {len(all_images)}\")\n",
    "\n",
    "# === æ¨è«–ã¨æŠ½å‡º ===\n",
    "selected = []\n",
    "random.shuffle(all_images)\n",
    "\n",
    "for img_path, true_idx in tqdm(all_images, desc=\"Selecting confident samples\"):\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    x = preprocess(img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(x)\n",
    "        probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "        top1_prob, top1_idx = torch.max(probs, 1)\n",
    "\n",
    "    if top1_idx.item() == true_idx and top1_prob.item() >= confidence_threshold:\n",
    "        selected.append((img_path, true_idx, imagenet_labels[true_idx], top1_prob.item()))\n",
    "\n",
    "    if len(selected) >= num_samples:\n",
    "        break\n",
    "\n",
    "print(f\"âœ… é¸ã°ã‚ŒãŸç”»åƒæ•°: {len(selected)}\")\n",
    "\n",
    "# === ä¿å­˜ ===\n",
    "rows = []\n",
    "for i, (src, label_id, label_name, prob) in enumerate(selected):\n",
    "    new_name = f\"sample{i+1:04d}.jpg\"\n",
    "    dst = os.path.join(output_dir, new_name)\n",
    "    shutil.copy(src, dst)\n",
    "    rows.append([new_name, label_id, label_name, f\"{prob:.4f}\"])\n",
    "\n",
    "with open(output_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"image\", \"label_id\", \"label_name\", \"confidence\"])\n",
    "    writer.writerows(rows)\n",
    "\n",
    "print(f\"\\nğŸ¯ é«˜ä¿¡é ¼åº¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã—ã¾ã—ãŸ â†’ {output_dir}\")\n",
    "print(f\"ğŸ§¾ ãƒ©ãƒ™ãƒ«CSV: {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b499f0a-c9cc-48ac-b814-7125a65a89cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:00<00:00, 73.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… æ¤œè¨¼å®Œäº†: 50 æš\n",
      "ğŸ¯ ä¸€è‡´ç‡ (Top-1): 100.00%\n",
      "ğŸ“„ æ¤œè¨¼çµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ â†’ C:\\Users\\sit\\wavelet_CGAN\\testdata3\\clean_dataset_50\\label_validation_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#æ¤œè¨¼ã‚³ãƒ¼ãƒ‰\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torchvision.transforms as T\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === è¨­å®š ===\n",
    "csv_path = r\"C:\\Users\\sit\\wavelet_CGAN\\testdata3\\clean_dataset_50\\clean_dataset_labels.csv\"\n",
    "img_dir = r\"C:\\Users\\sit\\wavelet_CGAN\\testdata3\\clean_dataset_50\"\n",
    "\n",
    "# === ãƒ¢ãƒ‡ãƒ« ===\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1)\n",
    "model = model.to(device).eval()\n",
    "imagenet_labels = models.MobileNet_V2_Weights.IMAGENET1K_V1.meta[\"categories\"]\n",
    "\n",
    "# === å‰å‡¦ç† ===\n",
    "preprocess = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# === CSVèª­è¾¼ ===\n",
    "df = pd.read_csv(csv_path)\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "# === æ¨è«–ã—ã¦ä¸€è‡´åˆ¤å®š ===\n",
    "results = []\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Validating\"):\n",
    "    filename = row[\"image\"]\n",
    "    true_id = int(row[\"label_id\"])\n",
    "    true_label = imagenet_labels[true_id]\n",
    "    img_path = os.path.join(img_dir, filename)\n",
    "    if not os.path.exists(img_path):\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        x = preprocess(img).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(x)\n",
    "            probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "            top1_prob, top1_idx = torch.max(probs, 1)\n",
    "            pred_label = imagenet_labels[top1_idx.item()]\n",
    "            pred_id = top1_idx.item()\n",
    "            prob = top1_prob.item()\n",
    "\n",
    "        is_correct = (pred_id == true_id)\n",
    "        results.append([filename, true_id, true_label, pred_id, pred_label, f\"{prob:.3f}\", is_correct])\n",
    "        total += 1\n",
    "        correct += int(is_correct)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ {filename} ã®æ¤œè¨¼ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "\n",
    "# === çµæœã¾ã¨ã‚ ===\n",
    "accuracy = correct / total * 100 if total > 0 else 0\n",
    "print(f\"\\nâœ… æ¤œè¨¼å®Œäº†: {total} æš\")\n",
    "print(f\"ğŸ¯ ä¸€è‡´ç‡ (Top-1): {accuracy:.2f}%\")\n",
    "\n",
    "# === çµæœä¿å­˜ ===\n",
    "output_path = os.path.join(os.path.dirname(csv_path), \"label_validation_results.csv\")\n",
    "pd.DataFrame(\n",
    "    results,\n",
    "    columns=[\"image\", \"true_id\", \"true_label\", \"pred_id\", \"pred_label\", \"probability\", \"is_match\"]\n",
    ").to_csv(output_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"ğŸ“„ æ¤œè¨¼çµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ â†’ {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01496a87-7313-4420-bceb-527da9d48f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1002/1002 [00:06<00:00, 155.43it/s]\n"
     ]
    }
   ],
   "source": [
    "#æ”»æ’ƒå‰ã®tensorã‚’ä½œã‚‹ã‚³ãƒ¼ãƒ‰\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "# === å…ƒç”»åƒã¨å‡ºåŠ›å…ˆ ===\n",
    "input_dir = Path(r\"C:\\Users\\sit\\wavelet_CGAN\\testdata3\\data3\")\n",
    "output_dir = Path(r\"C:\\Users\\sit\\wavelet_CGAN\\testdata3\\data3_clean_tensor\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# === transformï¼šAEç”Ÿæˆå‰ã¨æ•´åˆ (ToTensorã®ã¿) ===\n",
    "to_tensor = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),  # â†’ [0,1]\n",
    "])\n",
    "\n",
    "for fname in tqdm(sorted(os.listdir(input_dir))):\n",
    "    if not fname.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "        continue\n",
    "\n",
    "    img = Image.open(input_dir / fname).convert(\"RGB\")\n",
    "    tensor = to_tensor(img).unsqueeze(0)  # [1,3,H,W]\n",
    "    torch.save(tensor, output_dir / (Path(fname).stem + \".pt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1913e40-11c5-4943-b457-fd3f04df26d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:00<00:00, 213.06it/s]\n"
     ]
    }
   ],
   "source": [
    "#æ”»æ’ƒå‰ã®tensorã‚’ä½œã‚‹ã‚³ãƒ¼ãƒ‰\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "# === å…ƒç”»åƒã¨å‡ºåŠ›å…ˆ ===\n",
    "input_dir = Path(r\"C:\\Users\\sit\\wavelet_CGAN\\testdata3\\clean_dataset_50\")\n",
    "output_dir = Path(r\"C:\\Users\\sit\\wavelet_CGAN\\testdata3\\dataset_50_tensor\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# === transformï¼šAEç”Ÿæˆå‰ã¨æ•´åˆ (ToTensorã®ã¿) ===\n",
    "to_tensor = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),  # â†’ [0,1]\n",
    "])\n",
    "\n",
    "for fname in tqdm(sorted(os.listdir(input_dir))):\n",
    "    if not fname.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "        continue\n",
    "\n",
    "    img = Image.open(input_dir / fname).convert(\"RGB\")\n",
    "    tensor = to_tensor(img).unsqueeze(0)  # [1,3,H,W]\n",
    "    torch.save(tensor, output_dir / (Path(fname).stem + \".pt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4390702-bed8-44c3-acfa-e1ab99fe1c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. é«˜ä¿¡é ¼åº¦ç”»åƒã®æŠ½å‡ºã¨ä¿å­˜ ---\n",
      "ğŸ“¸ ç·ç”»åƒæ•°: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting confident samples:   9%|â–Š         | 864/10000 [00:13<02:26, 62.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… é¸ã°ã‚ŒãŸç”»åƒæ•°: 300\n",
      "ğŸ¯ é«˜ä¿¡é ¼åº¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã—ã¾ã—ãŸ â†’ C:\\Users\\sit\\wavelet_CGAN\\colab\\data2\n",
      "ğŸ§¾ ãƒ©ãƒ™ãƒ«CSV: C:\\Users\\sit\\wavelet_CGAN\\colab\\data2\\clean_dataset_labels.csv\n",
      "--------------------------------------------------\n",
      "--- 2. ãƒ©ãƒ™ãƒ«ã®å†æ¤œè¨¼ ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:04<00:00, 74.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… æ¤œè¨¼å®Œäº†: 300 æš\n",
      "ğŸ¯ ä¸€è‡´ç‡ (Top-1): 100.00%\n",
      "ğŸ“„ æ¤œè¨¼çµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ â†’ C:\\Users\\sit\\wavelet_CGAN\\colab\\data2\\label_validation_results.csv\n",
      "--------------------------------------------------\n",
      "--- 3. Tensorãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ: data2_tensor ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating tensors for data2_tensor: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 302/302 [00:01<00:00, 190.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ Tensorãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ â†’ C:\\Users\\sit\\wavelet_CGAN\\colab\\data2_tensor\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import csv\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "# === å…±é€šè¨­å®š ===\n",
    "# è­¦å‘Šã®æŠ‘åˆ¶ (MobileNetV2ã®weightsã®ä»•æ§˜å¤‰æ›´ã«é–¢ã™ã‚‹è­¦å‘Šãªã©)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# --- ãƒ‘ã‚¹è¨­å®š (å¿…è¦ã«å¿œã˜ã¦å¤‰æ›´ã—ã¦ãã ã•ã„) ---\n",
    "BASE_DIR = Path(r\"C:\\Users\\sit\\Downloads\\imagenetv2-matched-frequency\\imagenetv2-matched-frequency-format-val\")\n",
    "OUTPUT_ROOT_DIR = Path(r\"C:\\Users\\sit\\wavelet_CGAN\\colab\\data2\") # æŠ½å‡ºãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å‡ºåŠ›å…ˆ (æ¤œè¨¼ãƒ»Tensorç”Ÿæˆã®å…¥åŠ›å…ƒ)\n",
    "\n",
    "# --- æŠ½å‡º/ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ è¨­å®š ---\n",
    "NUM_SAMPLES = 300 # æŠ½å‡ºã™ã‚‹ç”»åƒæ•°\n",
    "CONFIDENCE_THRESHOLD = 0.8 # ç¢ºä¿¡åº¦ã®é–¾å€¤\n",
    "OUTPUT_CSV = OUTPUT_ROOT_DIR / \"clean_dataset_labels.csv\"\n",
    "\n",
    "# --- Tensorãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›è¨­å®š ---\n",
    "TENSOR_OUTPUT_DIR_2 = OUTPUT_ROOT_DIR.parent / f\"{OUTPUT_ROOT_DIR.name}_tensor\"# Tensorå‡ºåŠ›å…ˆ\n",
    "\n",
    "# === å…±é€šã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®åˆæœŸåŒ– ===\n",
    "# ãƒ‡ãƒã‚¤ã‚¹è¨­å®š\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ãƒ¢ãƒ‡ãƒ« (MobileNetV2)\n",
    "MODEL = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1)\n",
    "MODEL = MODEL.to(DEVICE).eval()\n",
    "IMAGENET_LABELS = models.MobileNet_V2_Weights.IMAGENET1K_V1.meta[\"categories\"]\n",
    "\n",
    "# ãƒ¢ãƒ‡ãƒ«ç”¨å‰å‡¦ç† (æŠ½å‡ºãƒ»æ¤œè¨¼ã§ä½¿ç”¨)\n",
    "PREPROCESS = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Tensorä½œæˆç”¨å‰å‡¦ç† (ToTensorã®ã¿)\n",
    "TO_TENSOR_ONLY = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),  # â†’ [0,1]\n",
    "])\n",
    "\n",
    "# === 1. é«˜ä¿¡é ¼åº¦ç”»åƒã®æŠ½å‡ºã¨ä¿å­˜ ===\n",
    "def extract_and_save_confident_images():\n",
    "    \"\"\"\n",
    "    æŒ‡å®šã•ã‚ŒãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ã€ãƒ¢ãƒ‡ãƒ«ãŒé«˜ç¢ºä¿¡åº¦ã§æ­£ã—ãåˆ†é¡ã—ãŸç”»åƒã‚’æŠ½å‡ºã—ã€\n",
    "    æ–°ã—ã„ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚³ãƒ”ãƒ¼ã—ã¦CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã™ã‚‹ã€‚\n",
    "    \"\"\"\n",
    "    print(\"--- 1. é«˜ä¿¡é ¼åº¦ç”»åƒã®æŠ½å‡ºã¨ä¿å­˜ ---\")\n",
    "    os.makedirs(OUTPUT_ROOT_DIR, exist_ok=True)\n",
    "    \n",
    "    # å…¨ç”»åƒãƒªã‚¹ãƒˆä½œæˆ\n",
    "    all_images = []\n",
    "    for class_id in os.listdir(BASE_DIR):\n",
    "        class_dir = BASE_DIR / class_id\n",
    "        if not class_dir.is_dir(): continue\n",
    "        try:\n",
    "            class_idx = int(class_id)\n",
    "        except ValueError:\n",
    "            continue\n",
    "        for img_name in os.listdir(class_dir):\n",
    "            if img_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                all_images.append((class_dir / img_name, class_idx))\n",
    "\n",
    "    print(f\"ğŸ“¸ ç·ç”»åƒæ•°: {len(all_images)}\")\n",
    "\n",
    "    # æ¨è«–ã¨æŠ½å‡º\n",
    "    selected = []\n",
    "    random.shuffle(all_images)\n",
    "\n",
    "    for img_path, true_idx in tqdm(all_images, desc=\"Selecting confident samples\"):\n",
    "        try:\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            x = PREPROCESS(img).unsqueeze(0).to(DEVICE)\n",
    "            with torch.no_grad():\n",
    "                outputs = MODEL(x)\n",
    "                probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "                top1_prob, top1_idx = torch.max(probs, 1)\n",
    "\n",
    "            if top1_idx.item() == true_idx and top1_prob.item() >= CONFIDENCE_THRESHOLD:\n",
    "                selected.append((img_path, true_idx, IMAGENET_LABELS[true_idx], top1_prob.item()))\n",
    "\n",
    "            if len(selected) >= NUM_SAMPLES:\n",
    "                break\n",
    "        except Exception as e:\n",
    "            # ãƒ•ã‚¡ã‚¤ãƒ«ç ´æç­‰ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—\n",
    "            # print(f\"âš ï¸ {img_path} å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}\") \n",
    "            continue\n",
    "\n",
    "    print(f\"âœ… é¸ã°ã‚ŒãŸç”»åƒæ•°: {len(selected)}\")\n",
    "\n",
    "    # ä¿å­˜\n",
    "    rows = []\n",
    "    for i, (src, label_id, label_name, prob) in enumerate(selected):\n",
    "        new_name = f\"sample{i+1:04d}.jpg\"\n",
    "        dst = OUTPUT_ROOT_DIR / new_name\n",
    "        shutil.copy(src, dst)\n",
    "        rows.append([new_name, label_id, label_name, f\"{prob:.4f}\"])\n",
    "\n",
    "    with open(OUTPUT_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"image\", \"label_id\", \"label_name\", \"confidence\"])\n",
    "        writer.writerows(rows)\n",
    "\n",
    "    print(f\"ğŸ¯ é«˜ä¿¡é ¼åº¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã—ã¾ã—ãŸ â†’ {OUTPUT_ROOT_DIR}\")\n",
    "    print(f\"ğŸ§¾ ãƒ©ãƒ™ãƒ«CSV: {OUTPUT_CSV}\")\n",
    "    print(\"-\" * 50)\n",
    "    return len(selected) > 0 # æˆåŠŸ/å¤±æ•—ãƒ•ãƒ©ã‚°\n",
    "\n",
    "# === 2. ãƒ©ãƒ™ãƒ«ã®å†æ¤œè¨¼ ===\n",
    "def validate_labels():\n",
    "    \"\"\"\n",
    "    æŠ½å‡ºã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®CSVã«åŸºã¥ãã€å†åº¦ãƒ¢ãƒ‡ãƒ«ã§æ¨è«–ã‚’è¡Œã„ã€\n",
    "    è¨˜éŒ²ã•ã‚ŒãŸãƒ©ãƒ™ãƒ«ã¨ã®ä¸€è‡´ç‡ï¼ˆTop-1ï¼‰ã‚’æ¤œè¨¼ã™ã‚‹ã€‚\n",
    "    \"\"\"\n",
    "    if not OUTPUT_CSV.exists():\n",
    "        print(f\"âš ï¸ æ¤œè¨¼ç”¨CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {OUTPUT_CSV}\")\n",
    "        return\n",
    "\n",
    "    print(\"--- 2. ãƒ©ãƒ™ãƒ«ã®å†æ¤œè¨¼ ---\")\n",
    "    \n",
    "    # CSVèª­è¾¼\n",
    "    df = pd.read_csv(OUTPUT_CSV)\n",
    "    df.columns = df.columns.str.strip().str.lower()\n",
    "    \n",
    "    # æ¨è«–ã—ã¦ä¸€è‡´åˆ¤å®š\n",
    "    results = []\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Validating\"):\n",
    "        filename = row[\"image\"]\n",
    "        true_id = int(row[\"label_id\"])\n",
    "        true_label = IMAGENET_LABELS[true_id]\n",
    "        img_path = OUTPUT_ROOT_DIR / filename\n",
    "        if not img_path.exists():\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            x = PREPROCESS(img).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = MODEL(x)\n",
    "                probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "                top1_prob, top1_idx = torch.max(probs, 1)\n",
    "                pred_label = IMAGENET_LABELS[top1_idx.item()]\n",
    "                pred_id = top1_idx.item()\n",
    "                prob = top1_prob.item()\n",
    "\n",
    "            is_correct = (pred_id == true_id)\n",
    "            results.append([filename, true_id, true_label, pred_id, pred_label, f\"{prob:.3f}\", is_correct])\n",
    "            total += 1\n",
    "            correct += int(is_correct)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ {filename} ã®æ¤œè¨¼ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "\n",
    "    # çµæœã¾ã¨ã‚\n",
    "    accuracy = correct / total * 100 if total > 0 else 0\n",
    "    print(f\"\\nâœ… æ¤œè¨¼å®Œäº†: {total} æš\")\n",
    "    print(f\"ğŸ¯ ä¸€è‡´ç‡ (Top-1): {accuracy:.2f}%\")\n",
    "\n",
    "    # çµæœä¿å­˜\n",
    "    output_path = OUTPUT_ROOT_DIR / \"label_validation_results.csv\"\n",
    "    pd.DataFrame(\n",
    "        results,\n",
    "        columns=[\"image\", \"true_id\", \"true_label\", \"pred_id\", \"pred_label\", \"probability\", \"is_match\"]\n",
    "    ).to_csv(output_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "    print(f\"ğŸ“„ æ¤œè¨¼çµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ â†’ {output_path}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# === 3. æ”»æ’ƒå‰ã®Tensorãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ ===\n",
    "def create_tensors(input_dir: Path, output_dir: Path, tensor_transform):\n",
    "    \"\"\"\n",
    "    æŒ‡å®šã•ã‚ŒãŸç”»åƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ç”»åƒã‚’PyTorch Tensorã«å¤‰æ›ã—ã€æŒ‡å®šã•ã‚ŒãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¿å­˜ã™ã‚‹ã€‚\n",
    "    \"\"\"\n",
    "    print(f\"--- 3. Tensorãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ: {output_dir.name} ---\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    if not input_dir.exists():\n",
    "        print(f\"âš ï¸ å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_dir}\")\n",
    "        return\n",
    "\n",
    "    for fname in tqdm(sorted(os.listdir(input_dir)), desc=f\"Creating tensors for {output_dir.name}\"):\n",
    "        if not fname.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            img = Image.open(input_dir / fname).convert(\"RGB\")\n",
    "            tensor = tensor_transform(img).unsqueeze(0)  # [1,3,H,W]\n",
    "            torch.save(tensor, output_dir / (Path(fname).stem + \".pt\"))\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ {fname} ã®Tensorä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "\n",
    "    print(f\"ğŸ’¾ Tensorãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ â†’ {output_dir}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# === ãƒ¡ã‚¤ãƒ³å‡¦ç† ===\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # 1. ç”»åƒã®æŠ½å‡ºã¨ä¿å­˜\n",
    "    is_extracted = extract_and_save_confident_images()\n",
    "    \n",
    "    if is_extracted:\n",
    "        # 2. ãƒ©ãƒ™ãƒ«ã®å†æ¤œè¨¼\n",
    "        validate_labels()\n",
    "\n",
    "        # 3. Tensorãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆï¼ˆâ˜… dataset_50_tensor ã®ã¿ï¼‰\n",
    "        create_tensors(OUTPUT_ROOT_DIR, TENSOR_OUTPUT_DIR_2, TO_TENSOR_ONLY)\n",
    "\n",
    "    else:\n",
    "        print(\"å‡¦ç†ã‚’ç¶šè¡Œã§ãã¾ã›ã‚“ã€‚é«˜ä¿¡é ¼åº¦ã®ç”»åƒãŒé¸æŠã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4140b509-b5cc-4b4b-bb8b-a254db6c8bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch260)",
   "language": "python",
   "name": "torch260"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
